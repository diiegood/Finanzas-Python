"Machine learning" 
"Regresion de arbol de decision"  #MODELO NO PARAMETRICO 

#conjunto de modelos parametricos -> se asume una relacion causal o funcion preestablecidas, no importa la interpretabilidad
#si no que el modelo funcione bastante y se adapte bastante bien a los datos disminuyendo el error

#conjunto de modelos no parametricos -> el modelo perderia interpretabilidad pero no hay relacion causal
#se disminuye el error que pueda tener, pero la regresion lineal , no se va conocer dependiendo del modelo
#aveces no va tener la interpretabilidad que se espera, mejores predictores de modelos.

#lo que interesa que haya un modelo que tenga gran interpretabilidad que se peuda explicar
#que tengan sentidos los resultados, explicandose de forma sencilla, 

#!pip install pydotplus  / libreria para machine learning

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score
from IPython.display import Image 

from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier, export_graphviz
from sklearn.ensemble import (
    BaggingClassifier, RandomForestClassifier,
    BaggingRegressor, RandomForestRegressor,
    GradientBoostingRegressor
)
from sklearn.metrics import mean_squared_error, confusion_matrix, classification_report

import six
import sys
import pydotplus
from io import StringIO  # En lugar de six.StringIO
plt.style.use("ggplot")


#se crea una funcion para el arbol
def print_tree (estimator, features, class_names=None, filled=True):
    tree = estimator
    names= features
    color = filled
    classn = class_names
    
    dot_data = StringIO()
    export_graphviz(estimator, out_file = dot_data, feature_names = features, class_names = classn,
                    filled = filled)
    graph = pydotplus.graph_from_dot_data(dot_data.getvalue())
    return(graph)



df = pd.read_csv("https://gist.githubusercontent.com/keeganhines/59974f1ebef97bbaa44fb19143f90bad/raw/d9bcf657f97201394a59fffd801c44347eb7e28d/Hitters.csv")
df = df.dropna()
df.info()
df.head(30)
#la variable a predecir es el salario.

X = df[['Years', 'Hits']] #regresores son los a√±os en la liga jugando y los hits que ha hecho cada jugador
Y = np.log(df.Salary)

#se grafican las variables de salario y de logaritmo de salario
fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (11,4))
ax1.hist(df.Salary)
ax1.set_xlabel('Salary')
ax2.hist(Y)
ax2.set_xlabel('log(Salary)')

#los datos estan concentrados a la izquierda pero tiene cesgo 
#los datos estan muy hacia la derecha

#se hace la regresion del arbol de decision
dtree = DecisionTreeRegressor(max_leaf_nodes = 3)
dtree.fit(X, Y)

dot_data = StringIO()
export_graphviz(dtree, 
                out_file=dot_data,
                filled = True,
                rounded = True, 
                special_characters= True)

graph = pydotplus.graph_from_dot_data(dot_data.getvalue())
Image(graph.create_png())







