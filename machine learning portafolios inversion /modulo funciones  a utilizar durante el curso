"""
Nota:
    
Al crear una funcion se debe cargar el modulo donde se encuentra y a su vez cargar la funcion a usar
cada vez que se crea una se debe reiniciar el programa para que la pueda correr sin problemas
correr primero el modulo de funciones y despues el principal.
"""



import pandas as pd
import numpy as np
from scipy.stats import norm

def drawdown(return_series: pd.Series):
    """Takes a time series of asset returns.
       returns a DataFrame with columns for
       the wealth index, 
       the previous peaks, and 
       the percentage drawdown
    """
    wealth_index = 1000*(1+return_series).cumprod()
    previous_peaks = wealth_index.cummax()
    drawdowns = (wealth_index - previous_peaks)/previous_peaks
    return pd.DataFrame({"Wealth": wealth_index, 
                         "Previous Peak": previous_peaks, 
                         "Drawdown": drawdowns})


def obtener_returnos():
    """
    Load the Fama-French Dataset for the returns of the Top and Bottom Deciles by MarketCap
    1- carga los datos panel
    2-filtra solo los valores de Lo-20 y Hi-20 del data frame
    3-se calculan los rendimientos de rendimientos/100
    4-se cambia el formato a serie de tiempo y se indexa el periodo
    5-regresa la funcion rets que es el dataframe ya filtrado con todo lo anterior
    """
    #se cargan los datos panel
    me_m = pd.read_csv(
       "C:/Users/creep/OneDrive/Escritorio/programacion/data/Portfolios_Formed_on_ME_monthly_EW.csv",
       header=0,
       index_col=0,
       parse_dates=True,
       na_values=-99.99)
    rets = me_m[['Lo 20', 'Hi 20']]
    #rets.columns = ['SmallCap', 'LargeCap']
    rets = me_m
    rets = rets/100
    rets.index = pd.to_datetime(rets.index, format="%Y%m").to_period('M')
    return rets


def returns():  #funcion para leer base de datos
    """
    Load and format the EDHEC Hedge Fund Index Returns
    """
    hfi = pd.read_csv("C:/Users/creep/OneDrive/Escritorio/programacion/data/edhec-hedgefundindices.csv",
                      header=0, index_col=0, parse_dates=True)
    hfi = hfi/100
    hfi.index = hfi.index.to_period('M')
    return hfi


def skewness(r):
    """
    Alternative to scipy.stats.skew()
    Computes the skewness of the supplied Series or DataFrame
    Returns a float or a Series
    """
    demeaned_r = r - r.mean()
    # use the population standard deviation, so set dof=0
    sigma_r = r.std(ddof=0)
    exp = (demeaned_r**3).mean()
    return exp/sigma_r**3


def kurtosis(r):
    """
    Alternative to scipy.stats.kurtosis()
    Computes the kurtosis of the supplied Series or DataFrame
    Returns a float or a Series
    """
    demeaned_r = r - r.mean() 
    # use the population standard deviation, so set dof=0
    sigma_r = r.std(ddof=0)
    exp = (demeaned_r**4).mean()
    return exp/sigma_r**4

import scipy.stats
def is_normal(r, level=0.01):
    """
    Applies the Jarque-Bera test to determine if a Series is normal or not
    Test is applied at the 1% level by default
    Returns True if the hypothesis of normality is accepted, False otherwise
    """
    if isinstance(r, pd.DataFrame):
        return r.aggregate(is_normal)
    else:
        statistic, p_value = scipy.stats.jarque_bera(r)
        return p_value > level

def semi_desviacion(r):
    """
    los rendimientos con semi-desviacion o semidesvaicion negativa de r
    deben ser series o un data frame
    """
    is_negative = r<0
    return r[is_negative].std(ddof=0)

#r son los rendimientos
#level es el valor del percentil donde se va parar para sacar el VaR
def VaR_historico(r, level=5):
    """
    VaR historico
    """
    if isinstance(r, pd.DataFrame):
        return r.aggregate(VaR_historico, level=level)
    
    elif isinstance(r, pd.Series):
        return -np.percentile(r, level)
    else:
        raise TypeError("no seas wey")

      
    
def VaR_Normal (r, level=5):
    """
    Calcula el VaR con retornos usando modelo parametrico de la distribucion normal
    """
    #para calcular el valor z de la distribucion si fuera normal
    valor_dist_norm = norm.ppf(level/100)
    return -(r.mean() + valor_dist_norm*r.std(ddof=0))


def VaR_mejorado(r, level=5, modified= False):
    """
    Rendimientos parametricos del VaR Gaussiano en una serie o un dataframe
    si se modifica es verdadero despues se modifica el VaR de los retornos
    """
    #calcular el valor z asumiendo la distribucion normal
    z = norm.ppf(level/100)
    if modified:
        #modifica el valor z basado en la curtosis y la asimetria observada
        s = skewness(r)
        k = kurtosis(r)
        z = (z+ (z**2 -1)*s/6 + (z**3 - 3*z)*(k-3)/24-(2*z**3-5*z)*(s**2)/36)
        return -(r.mean()+z*r.std(ddof=0))
    
def semideviation3(r):
    """
    Returns the semideviation aka negative semideviation of r
    r must be a Series or a DataFrame, else raises a TypeError
    """
    excess= r-r.mean()                                        # We demean the returns
    excess_negative = excess[excess<0]                        # We take only the returns below the mean
    excess_negative_square = excess_negative**2               # We square the demeaned returns below the mean
    n_negative = (excess<0).sum()                             # number of returns under the mean
    return (excess_negative_square.sum()/n_negative)**0.5     

def C_VaR_historico(r, level =5):
    """
    Calcula el VaR condicional de las series del dataframe
    """
    if isinstance(r, pd.Series):
        is_beyond = r <= -VaR_historico(r, level=level)
        return -r[is_beyond].mean()
    elif isinstance(r, pd.DataFrame):
        return r.aggregate(C_VaR_historico, level=level)
    else:
        raise TypeError("Expected r to be a Series or DataFrame")
        
        
###############################################################################

def cargar_datos():
    """
    Carga los datos a utilizar en el modulo dos del rendimiento de la industria
    """
    datos = pd.read_csv("C:\\Users\\creep\\OneDrive\\Escritorio\\programacion\\data\\ind30_m_vw_rets.csv",
                        header = 0,
                        index_col = 0,
                        parse_dates=True)/100
    datos.index = pd.to_datetime(datos.index, format="%Y%m").to_period("M")
    datos.columns = datos.columns.str.strip()
    return datos


def volatilidad_anualizada(r, periodos_año):
    """
    Anualiza la volatilidad sobre los rendimientos
    se hace inferencia en los periodos por año
    """
    return r.std()*(periodos_año**0.5)



def rendimientos_anualizados(r, periodos_año):
    """
    Anualiza los rendimeintos donde se hace inferencia por año
    """
    periodos_año = 12 #
    compounded_growth = (1+r).prod()
    numero_periodos = r.shape[0]
    return compounded_growth**(periodos_año/numero_periodos)


def sharpe_ratio(r, risk_free_rate, periodos_año):
    """
    Se calcula el sharpe ratio de los rendimientos anualizados
    """
    periodos_año = 12 #
    risk_free_periodo = (1+risk_free_rate)**(1/periodos_año)-1 
    excess_ret = r - risk_free_periodo
    ann_ex_ret = rendimientos_anualizados(excess_ret, periodos_año)
    ann_vol = volatilidad_anualizada(r, periodos_año)
    return ann_ex_ret, ann_vol


    
    
    
    
    
    
    
    
    
    
    
